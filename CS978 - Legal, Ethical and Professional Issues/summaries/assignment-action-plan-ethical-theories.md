---
title: "Assignment Action Plan - Ethical Theories & Privacy Values"
module: "CS978"
tags: [module/CS978, type/summaries, assignment, ethics]
date: 2025-10-26
deadline: 2025-11-06 12:00
---

# CS978 Assignment Action Plan
## Section 4: Ethical Theories and Privacy Values

üéØ **Deadline:** Thursday, November 6th, 2025 at 12:00PM (11 days!)
üìπ **Format:** Video presentation (10 minutes total for whole team)
üé§ **Your estimated time:** ~2 minutes of the video

---

## üéØ Your Core Task

**Section:** 4. Ethical Theories and Privacy Values

**Focus:** Apply ethical frameworks to analyze privacy in AI training data

**Central Question You Must Answer:**
> "Is it morally justified to use publicly available personal data for AI training?"

**Target Audience:** Regulatory bodies and companies developing AI products

**Required Frameworks:**
1. Deontology (Kant)
2. Utilitarianism (Bentham/Mill)
3. Virtue Ethics (Aristotle)
4. Data Ethics (Floridi)

**Key References:**
- Floridi (2013) - Data ethics framework
- Mittelstadt et al. (2016) - Ethics of algorithms

**Optional Addition:**
- Section 6: Governance & Policy Recommendations (if no one else is doing this)

---

## ‚ö†Ô∏è Critical Constraints

**What you CANNOT do:**
‚ùå Use AI to generate presentation content
‚ùå Use AI-generated images
‚ùå Copy/paste from course materials without analysis
‚ùå Give one-sided ethical arguments

**What you MUST do:**
‚úÖ Read academic sources (Floridi, Mittelstadt)
‚úÖ Apply ALL FOUR frameworks to the question
‚úÖ Show nuance - each framework reaches different conclusions
‚úÖ Connect to real examples (ChatGPT, Clearview AI)
‚úÖ Make it relevant to your target audience (regulators/AI companies)

---

## üìö Phase 1: Understanding the Frameworks (Days 1-3)

### Step 1.1: Master Deontology (Kantian Ethics)

**What you need to understand:**

Deontology = duty-based ethics. Actions are inherently right or wrong, regardless of consequences.

**Key Concepts to Grasp:**
1. **Categorical Imperative** - "Act only according to that maxim whereby you can, at the same time, will that it should become a universal law"
   - Translation: Would you want everyone to do this action?

2. **Treating humans as ends, not means** - "Never treat humanity merely as a means to an end"
   - Translation: Don't use people just for your benefit without considering their interests

3. **Duty and moral absolutes** - Some actions are simply wrong, full stop

**Your Reading Task:**
- [ ] Re-read Week 3 materials on deontological ethics (in your reading materials file)
- [ ] Focus on the Kant sections - take notes on the two maxims
- [ ] Write down in YOUR OWN WORDS what the categorical imperative means

**Apply to AI Question:**

Ask yourself (and write notes):
1. If every AI company scraped publicly available data without consent, would this be acceptable as a universal law?
2. Are AI companies treating individuals as "ends" or just as "means" (data sources)?
3. Does "publicly available" = "ethically usable"? Why/why not from Kant's perspective?
4. Is there a DUTY to respect privacy even for public data?

**What Kant Would Likely Say:**
- Think about this yourself first, then check your reasoning
- Consider: Does scraping data treat people's dignity with respect?
- Does it violate the principle of informed consent?

---

### Step 1.2: Master Utilitarianism (Consequentialist Ethics)

**What you need to understand:**

Utilitarianism = greatest happiness for greatest number. Outcomes matter, not intentions.

**Key Concepts to Grasp:**
1. **Greatest happiness principle** - Maximize overall wellbeing/utility
2. **Act vs Rule Utilitarianism**
   - Act: Judge each individual action by its consequences
   - Rule: Follow rules that generally maximize utility
3. **The minority can suffer** if it benefits the majority

**Your Reading Task:**
- [ ] Re-read Week 3 materials on utilitarianism
- [ ] Note the difference between Bentham and Mill's versions
- [ ] Think about the "trolley problem" - connects well to AI ethics

**Apply to AI Question:**

Make a **Utility Balance Sheet** (do this yourself on paper):

**Positive Consequences (Benefits):**
- Who benefits from AI trained on public data?
  - List: AI companies, users of AI services, researchers, society...
- What are the benefits?
  - Better AI, medical advances, accessibility, efficiency...
- How many people benefit?
  - Potentially millions/billions

**Negative Consequences (Harms):**
- Who is harmed?
  - People whose data is scraped, vulnerable groups, minorities...
- What are the harms?
  - Privacy invasion, bias perpetuation, lack of control...
- How many people are harmed?
  - Could be millions, but less than benefit?

**Your Analysis Task:**
- [ ] Does the benefit outweigh the harm?
- [ ] From a utilitarian view, is using public data justified?
- [ ] What if the data includes sensitive information about vulnerable groups?
- [ ] Does Act Utilitarianism give a different answer than Rule Utilitarianism?

**What a Utilitarian Would Likely Say:**
- Think through this yourself
- Consider: Can you maximize utility AND protect privacy?
- What about differential privacy or federated learning as compromises?

---

### Step 1.3: Master Virtue Ethics (Aristotelian Ethics)

**What you need to understand:**

Virtue Ethics = focus on character and virtues, not rules or outcomes. What would a virtuous person do?

**Key Concepts to Grasp:**
1. **Eudaimonia** (human flourishing/happiness)
2. **The Golden Mean** - virtue is balance between excess and deficiency
3. **Virtue is context-dependent** - right action depends on circumstances
4. **Character over rules** - Be a good person, not just follow rules

**Your Reading Task:**
- [ ] Re-read Week 3 materials on virtue ethics
- [ ] Note why it's harder to apply to professional ethics
- [ ] Think about what virtues an AI developer should have

**Apply to AI Question:**

**Identify Relevant Virtues:**
Ask yourself - what virtues matter for AI developers?
- Honesty?
- Respect?
- Prudence (practical wisdom)?
- Justice?
- Temperance (moderation)?

**Your Analysis Task:**
- [ ] What would a virtuous AI developer do about using public data?
- [ ] Where is the "golden mean" between:
  - **Excess:** Scraping everything without thought (reckless)
  - **Deficiency:** Never using any data (overcautious)
  - **Virtue:** ? (you figure this out)

- [ ] Does using public data demonstrate virtuous character?
- [ ] What about the virtue of the COMPANY, not just the individual?

**What Virtue Ethics Would Likely Say:**
- Less clear than the other frameworks
- Think: Does this action reflect good professional character?
- What virtues are we cultivating in AI development culture?

---

### Step 1.4: Master Data Ethics (Floridi Framework)

**What you need to understand:**

Data Ethics = modern framework specific to information/data contexts

**THIS IS YOUR MOST IMPORTANT REFERENCE - Floridi (2013)**

**Your Reading Strategy:**

**Priority Reading:**
- [ ] Find and download Floridi (2013) - "The Ethics of Information"
  - Search your university library database
  - Key chapters: Focus on "information ethics" and "privacy"

**What to Extract from Floridi:**
- [ ] What makes data ethics different from traditional ethics?
- [ ] Floridi's principles for information ethics
- [ ] His view on privacy as informational self-determination
- [ ] Concept of "informational friction" and "greased information"

**Key Concepts from Floridi:**
1. **Informational privacy** - Control over your information
2. **Ontological friction** - The "cost" of accessing information
3. **Information as identity** - Our data represents us
4. **Four moral principles**:
   - Entropy should not be caused
   - Entropy should be prevented
   - Entropy should be removed
   - The flourishing of informational entities should be promoted

**Apply to AI Question:**

- [ ] Does scraping public data reduce "ontological friction" too much?
- [ ] Should there be some barrier/friction even for public data?
- [ ] Does using public data for AI promote or harm informational flourishing?
- [ ] How does Floridi's framework differ from Kant/Mill?

**Mittelstadt et al. (2016) - "The Ethics of Algorithms"**

**Your Reading Strategy:**
- [ ] Find and download this paper
- [ ] Focus on the sections about:
  - Inconclusive evidence
  - Inscrutable evidence
  - Transformative effects

**What to Extract:**
- [ ] How do they categorize algorithmic ethics issues?
- [ ] Their framework for analyzing ethical concerns
- [ ] Connection to your question about training data

**Apply to AI Question:**
- [ ] Does their framework reveal ethical issues with using public data?
- [ ] How do training data decisions affect algorithmic outcomes?
- [ ] Connection to bias, discrimination, fairness

---

## üéØ Phase 2: Comparative Analysis (Days 4-5)

### Step 2.1: Create Your Framework Comparison

**Task:** Build a comparison table (do this yourself on paper/Word)

| Framework | Is it justified? | Key Reasoning | Conditions/Caveats |
|-----------|-----------------|---------------|-------------------|
| Deontology | Yes/No/Depends | Why? | Under what circumstances? |
| Utilitarianism | Yes/No/Depends | Why? | When does balance shift? |
| Virtue Ethics | Yes/No/Depends | Why? | What virtues are at stake? |
| Data Ethics (Floridi) | Yes/No/Depends | Why? | What principles apply? |

**Fill this out YOURSELF based on your reading and thinking**

### Step 2.2: Identify Points of Conflict

**Your Analysis Task:**

Where do the frameworks disagree?

Example questions to explore:
- Does Kant say "never justified" while utilitarians say "sometimes justified"?
- Does Floridi add nuance that Kant misses?
- Do virtue ethics give a middle ground?

**This is where your presentation gets interesting!**

Show your audience:
- Ethical questions rarely have simple answers
- Different frameworks lead to different conclusions
- Professionals need to navigate these tensions

### Step 2.3: Find Real-World Examples

**Connect your ethical analysis to actual cases:**

From your group plan, you have:
1. **ChatGPT (Italy, 2023)** - suspended for inadequate transparency
2. **Clearview AI** - fined for scraping facial images

**Your Research Task:**
- [ ] Google these cases - find news articles and official reports
- [ ] For each case, ask:
  - Which ethical framework would condemn this?
  - Which might justify it?
  - What was the actual regulatory response?

**Additional Examples to Research:**
- [ ] Common Crawl dataset (used by many AI models)
- [ ] Getty Images vs AI art generators
- [ ] Reddit data used to train language models
- [ ] Facial recognition trained on social media photos

**For Each Example, Note:**
- What data was used?
- Was it "publicly available"?
- What were the ethical concerns?
- What was the outcome?

---

## üé¨ Phase 3: Presentation Planning (Days 6-8)

### Step 3.1: Structure Your Section

**Your ~2 minutes should cover:**

**Opening (15 seconds):**
- State the ethical question clearly
- Why it matters to your audience (regulators/AI companies)

**Framework 1: Deontology (20-25 seconds):**
- 1 sentence: What is deontology?
- 2-3 sentences: How does it apply to AI training data?
- Your conclusion: Justified or not from this view?

**Framework 2: Utilitarianism (20-25 seconds):**
- 1 sentence: What is utilitarianism?
- 2-3 sentences: Balance of harms/benefits
- Your conclusion: When is it justified from this view?

**Framework 3: Virtue Ethics (15-20 seconds):**
- 1 sentence: What is virtue ethics?
- 2-3 sentences: What virtues matter? Golden mean?
- Your conclusion: What would a virtuous developer do?

**Framework 4: Data Ethics/Floridi (20-25 seconds):**
- 1 sentence: What makes data ethics distinct?
- 2-3 sentences: Floridi's principles applied
- Your conclusion: His framework's guidance

**Synthesis (15-20 seconds):**
- These frameworks don't all agree
- Professionals must navigate this complexity
- Bridge to next section or governance recommendations

**Total: ~120 seconds (2 minutes)**

### Step 3.2: Draft Your Script

**DO THIS YOURSELF - don't use AI**

**Writing Strategy:**

1. **Write down key points** for each framework (bullet points)
2. **Speak them out loud** - record yourself on phone
3. **Listen back** - does it make sense? Is it clear?
4. **Time yourself** - are you over/under 2 minutes?
5. **Revise** - make it tighter or add examples
6. **Practice** 5-10 times until you can speak naturally

**Tone for Your Audience:**
- Professional but accessible
- Avoid overly academic jargon
- Explain frameworks simply (your audience may not know Kant)
- Use concrete examples (ChatGPT, Clearview)
- Show practical implications

### Step 3.3: Design Your Slides

**Slide Recommendations:**

**Slide 1: Title**
```
Ethical Theories and Privacy Values
Is it morally justified to use publicly available
personal data for AI training?
```

**Slide 2: Four Frameworks**
```
1. Deontology (Kant) - Duty-based ethics
2. Utilitarianism (Mill) - Consequences matter
3. Virtue Ethics (Aristotle) - Character focus
4. Data Ethics (Floridi) - Information-specific
```

**Slides 3-6: One per framework**
Each slide should have:
- Framework name
- 1-2 key principles (brief!)
- Visual icon or diagram (NOT AI-generated!)
- Your conclusion in a box

**Slide 7: Comparison**
```
Table or diagram showing:
- Where frameworks agree
- Where they conflict
- Implications for AI developers
```

**Design Tips:**
- Keep text minimal (you're speaking, not reading)
- Use simple graphics (find license-free images on Unsplash, Wikimedia Commons)
- Clear fonts, good contrast
- Reference citations at bottom in small text

---

## üèõÔ∏è Phase 4: Governance Recommendations (Optional - Days 9-10)

**If you're also covering Section 6:**

### Your Task: Bridge Ethics to Policy

**Structure:**

**From Ethical Analysis to Practical Recommendations:**

For each framework you discussed, derive 1-2 practical recommendations:

**Example Structure (do this properly yourself):**

**From Deontology:**
- Recommendation: Implement informed consent mechanisms
- Why: Respects individual dignity and autonomy
- How: Opt-in for data usage, clear notices

**From Utilitarianism:**
- Recommendation: Conduct cost-benefit assessments
- Why: Maximize overall utility
- How: DPIAs (Data Protection Impact Assessments)

**From Data Ethics:**
- Recommendation: Build "informational friction"
- Why: Floridi's principle of responsible data access
- How: Rate limiting, access controls, audit logs

**Concrete Policies to Recommend:**

Research and present:
- [ ] Differential Privacy techniques
- [ ] Federated Learning approaches
- [ ] Data provenance requirements
- [ ] Audit and accountability mechanisms
- [ ] Transparency requirements

**Connection to Legal Section:**
- Your team members covered GDPR, UK DPA, EU AI Act
- Show how ethical principles SUPPORT legal compliance
- Ethics goes beyond legal minimum

**Your Governance Slide(s):**

**Slide: Ethical Foundations for Policy**
```
Ethical Principle ‚Üí Policy Recommendation
[Diagram showing mapping]
```

**Slide: Practical Recommendations**
```
For Regulators:
- Require DPIAs for AI training data
- Mandate transparency in data sources
- Enforce accountability mechanisms

For AI Companies:
- Implement differential privacy
- Conduct ethical audits
- Build trust through transparency
```

---

## üìñ Reading Strategy & Timeline

### Days 1-2: Core Reading
- [ ] Week 3 course materials (deontology, utilitarianism, virtue ethics)
- [ ] Take detailed notes on each framework
- [ ] Write summary in your own words

### Days 3-4: Academic Reading
- [ ] Floridi (2013) - focus on key chapters
- [ ] Mittelstadt et al. (2016) - read fully
- [ ] Take notes on how they apply to AI question

### Days 5-6: Research Examples
- [ ] ChatGPT Italy case
- [ ] Clearview AI case
- [ ] Other relevant examples
- [ ] Note ethical dimensions of each

### Days 7-8: Create Presentation
- [ ] Write script (draft, revise, time)
- [ ] Design slides
- [ ] Practice delivery
- [ ] Get feedback from teammate

### Days 9-10: Governance (if doing Section 6)
- [ ] Derive recommendations from ethical analysis
- [ ] Research practical implementations
- [ ] Create governance slides

### Day 11: Final Rehearsal
- [ ] Full team practice
- [ ] Time the whole presentation
- [ ] Refine transitions
- [ ] Record and submit

---

## ‚úÖ Quality Checklist

### Content Quality

**Before you finalize, check:**

- [ ] Have I explained each framework clearly?
- [ ] Did I apply ALL FOUR frameworks to the question?
- [ ] Do I show where frameworks agree AND disagree?
- [ ] Did I use real examples (ChatGPT, Clearview)?
- [ ] Is it relevant to my audience (regulators/AI companies)?
- [ ] Did I cite Floridi and Mittelstadt properly?
- [ ] Did I go beyond course materials (as required)?
- [ ] Is my analysis nuanced, not simplistic?

**Ethical Analysis Quality:**
- [ ] Did I fairly represent each framework?
- [ ] Did I avoid strawman arguments?
- [ ] Did I show complexity, not just "right vs wrong"?
- [ ] Did I connect theory to practice?

**Presentation Quality:**
- [ ] Is my script clear and well-paced?
- [ ] Are my slides visually appealing?
- [ ] No AI-generated images?
- [ ] Proper citations on slides?
- [ ] No grammatical errors?
- [ ] Voice is clear and confident?

---

## üéØ Success Criteria (From Marking Scheme)

**For 70-80% (Distinction):**

Your section should demonstrate:
- ‚úÖ Excellent analysis of range of relevant ethical issues
- ‚úÖ Key points fully developed to reach valid conclusion
- ‚úÖ Logical structure and line of reasoning
- ‚úÖ Info supported by evidence and appropriate exemplars
- ‚úÖ Evidence of reading that goes beyond course materials

**For 80%+ (High Distinction):**

Your section should demonstrate:
- ‚úÖ **Outstanding** analysis of **wide range** of ethical issues
- ‚úÖ **Insightful** conclusions
- ‚úÖ **Very well-developed** logical reasoning
- ‚úÖ Info **substantiated** with evidence

**How to Reach This:**
- Don't just describe frameworks - ANALYZE them
- Show tensions and contradictions
- Use multiple real examples
- Connect Floridi's modern framework to classical ethics
- Show implications for your target audience
- Make novel connections (e.g., virtue ethics applied to corporate culture)

---

## üí° Pro Tips

### Working Without AI Content Generation

**What you CAN use AI for:**
- ‚úÖ Finding sources (e.g., "Where can I find Floridi's 2013 paper?")
- ‚úÖ Clarifying concepts (e.g., "Explain the categorical imperative")
- ‚úÖ Grammar checking (Grammarly)
- ‚úÖ Citation formatting (APA style questions)

**What you CANNOT use AI for:**
- ‚ùå Writing your script
- ‚ùå Generating slide content
- ‚ùå Creating your ethical analysis
- ‚ùå Making images

**When in doubt:** If it feels like AI is doing the thinking for you, don't use it.

### Making It Engaging

**For Your Audience (Regulators/AI Companies):**

**Don't:** Give abstract philosophy lecture
**Do:** Show practical implications

**Examples of Engaging Approaches:**
- "If you're developing AI, here's why Kant would challenge your approach..."
- "As a regulator, utilitarianism might justify this, BUT deontology reveals a problem..."
- "Clearview AI learned this the hard way when..."
- "Floridi's framework offers a modern lens that traditional ethics miss..."

### Voice and Delivery

**Practice these techniques:**
- Vary your pace (slow down for key points)
- Use pauses for emphasis
- Show enthusiasm for the topic
- Look at camera, not just slides
- Use hand gestures if comfortable
- Smile - you're teaching, not lecturing

---

## üìö Reference Management

### Keep Track of All Sources

**Format: APA Style**

**Example Citations You'll Need:**

**Floridi:**
```
Floridi, L. (2013). The ethics of information.
Oxford University Press.
```

**Mittelstadt:**
```
Mittelstadt, B. D., Allo, P., Taddeo, M., Wachter, S.,
& Floridi, L. (2016). The ethics of algorithms: Mapping
the debate. Big & Open Data, 3(2), 1-25.
```

**Course Materials:**
```
Nicol, E. (2025). Week 3: Ethical values [Lecture notes].
CS978 Legal, Ethical and Professional Issues.
University of Strathclyde.
```

**Keep a Running List:**
- Every source you read
- Every example you mention
- Every case you reference

**On Your Slides:**
- Small citations at bottom
- Full reference list on final slide

---

## ü§ù Team Coordination

### Your Section Connects To:

**Legal Sections (1-3):**
- They cover GDPR, consent, enforcement
- You cover the ethical "why behind the law"
- Your ethics should support their legal analysis

**Professional Responsibility (5):**
- Connects to your virtue ethics discussion
- Professional codes (ACM, BCS) reflect ethical principles
- Show how deontology informs professional duties

**Governance Recommendations (6):**
- YOUR ethical analysis justifies the recommendations
- Show: Ethics ‚Üí Principles ‚Üí Policy

**Coordinate With Team:**
- [ ] Share your draft script with team
- [ ] Check for overlaps/gaps
- [ ] Ensure smooth transitions
- [ ] Practice together

**Transition Into Your Section:**
- Previous person likely ends with legal enforcement
- You could start: "These legal requirements rest on deeper ethical foundations..."

**Transition Out of Your Section:**
- End with: "These ethical frameworks inform professional responsibilities..."
- Or: "From these ethical principles, we can derive governance recommendations..."

---

## üé¨ Recording Tips

### When You Record:

**Technical:**
- [ ] Good lighting (face camera toward window or lamp)
- [ ] Clear audio (use headphones with mic if possible)
- [ ] Share screen for slides
- [ ] Record yourself (picture-in-picture)
- [ ] Test audio/video BEFORE final recording

**Delivery:**
- [ ] Sit up straight
- [ ] Look at camera (not slides)
- [ ] Speak clearly and pace yourself
- [ ] Don't rush
- [ ] Take a breath before starting
- [ ] Smile occasionally

---

## ‚è∞ Timeline Summary

| Day | Task | Deliverable |
|-----|------|-------------|
| 1-2 | Read course materials on ethical frameworks | Notes on 3 frameworks |
| 3-4 | Read Floridi & Mittelstadt | Notes on data ethics |
| 5 | Research real cases | Example notes |
| 6 | Apply frameworks to AI question | Comparison table |
| 7 | Draft script | Written script |
| 8 | Design slides | Slide deck |
| 9 | (Optional) Governance section | Policy recommendations |
| 10 | Team practice | Feedback incorporated |
| 11 | Final recording & submit | Submitted video |

---

## üîó Related Materials

**In Your Obsidian Vault:**
- [[assignment-brief]] - Full assignment requirements
- [[group-plan]] - Team structure and responsibilities
- Reading materials file (on Desktop - too large for Obsidian)

**To Find:**
- Floridi (2013) - University library database
- Mittelstadt et al. (2016) - University library or Google Scholar
- ChatGPT Italy case - Google News
- Clearview AI case - Reuters, GDPR enforcement tracker

---

## ‚ùì Questions to Ask Yourself

**As you work, keep asking:**

1. Am I just describing frameworks, or analyzing them?
2. Have I gone beyond course materials?
3. Is this relevant to regulators and AI companies?
4. Would the teacher know I used AI? (If yes, revise)
5. Am I showing nuance or being simplistic?
6. Have I cited my sources properly?
7. Can I explain this clearly in 2 minutes?

---

## üö® Red Flags to Avoid

**Warning signs you're off track:**

‚ùå Script sounds like ChatGPT wrote it (too formal, generic)
‚ùå Just listing what each framework says (not applying to question)
‚ùå Only using course materials (need Floridi & Mittelstadt)
‚ùå One-sided argument (show multiple perspectives)
‚ùå Too abstract (need concrete examples)
‚ùå Over time (practice and cut)
‚ùå Slides have paragraphs of text (keep minimal)

---

**You've got this!** üéì

Remember:
- This is about YOUR thinking, not AI's
- Show you understand the frameworks deeply
- Apply them to a real, complex question
- Demonstrate nuance and critical analysis
- Make it relevant to your audience

**If you get stuck:** Re-read the source material, think through examples, discuss with teammates. The struggle is part of learning - embrace it!

---

*Created: 2025-10-26*
*Based on: Assignment brief, group plan, and course materials*
*Target: 70-80% distinction-level work*
